{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.2: Stylistic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lab, we have seen how to extract information about the syntactic structure of sentences. In this lab, we show a few more examples for extracting stylistic features. We provide examples for three simple stylistic features, but this is just the start. **Think about stylistic features that could characterize your dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 13:44:59 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59956b74cff4d66b51c14e11694d73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 13:44:59 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2023-10-25 13:44:59 INFO: Using device: cpu\n",
      "2023-10-25 13:44:59 INFO: Loading: tokenize\n",
      "2023-10-25 13:44:59 INFO: Loading: pos\n",
      "2023-10-25 13:45:00 INFO: Loading: lemma\n",
      "2023-10-25 13:45:00 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import stanza\n",
    "import string\n",
    "\n",
    "# Read in TSV\n",
    "tsv_file = \"../data/veganism_overview_en.tsv\"\n",
    "news_content = pd.read_csv(tsv_file, sep=\"\\t\", keep_default_na=False, header=0)\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,pos,lemma')\n",
    "\n",
    "# We filter out empty articles\n",
    "news_content = news_content[news_content[\"Text\"].str.len() >0 ]\n",
    "articles = news_content[\"Text\"]\n",
    "processed_articles = []\n",
    "for article in articles:\n",
    "    processed_articles.append(nlp.process(article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we extract information from the MRC database. This database contains many types of psycholinguistic features for English words. Download the file [mrc.dct](https://github.com/samzhang111/mrc-psycholinguistics/blob/master/mrc2.dct) and save it in your data folder. As an example, we extract the concreteness ratings.\n",
    "\n",
    "**Check the [documentation](https://websites.psychology.uwa.edu.au/school/MRCDatabase/mrc2.html#CONC) and figure out the meaning of the features. What does it mean if a text has a high level of average concreteness?**\n",
    "\n",
    "Note: some browsers save *mrc.dct* as *mrc.dct.txt*. Make sure to adjust either the filename or the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def load_mrc():\n",
    "    words ={}\n",
    "    print(\"Start loading...\")\n",
    "    for line in open('../data/mrc2.dct','r'):\n",
    "\n",
    "        # This code is from https://github.com/samzhang111/mrc-psycholinguistics/blob/master/extract.py\n",
    "        word, phon, dphon, stress = line[51:].split('|')\n",
    "\n",
    "        nlet = int(line[0:2])\n",
    "        nphon = int(line[2:4])\n",
    "        nsyl = int(line[4])\n",
    "        kf_freq = int(line[5:10])\n",
    "        kf_ncats = int(line[10:12])\n",
    "        kf_nsamp = int(line[12:15])\n",
    "        tl_freq = int(line[15:21])\n",
    "        brown_freq = int(line[21:25])\n",
    "        fam = int(line[25:28])\n",
    "        conc = int(line[28:31])\n",
    "        imag = int(line[31:34])\n",
    "        meanc = int(line[34:37])\n",
    "        meanp = int(line[37:40])\n",
    "        aoa = int(line[40:43])\n",
    "        tq2 = line[43]\n",
    "        wtype = line[44]\n",
    "        pdwtype = line[45]\n",
    "        alphasyl = line[46]\n",
    "        status = line[47]\n",
    "        var = line[48]\n",
    "        cap = line[49]\n",
    "        irreg = line[50]\n",
    "\n",
    "        # For this example, we only extract the concreteness rating, but you might try other features\n",
    "        # In this case, you could save a tuple as value for each word in the dictionary\n",
    "        words[word.lower()] = int(conc)\n",
    "    print(\"Done.\")\n",
    "    return words\n",
    "mrc = load_mrc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that calculates the mean concreteness for a list of tokens. Tokens which do not have a concreteness rating in the MRC database are ignored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def calculate_concreteness(tokens, mrc_concreteness):\n",
    "    concreteness = []\n",
    "    for token in tokens:\n",
    "\n",
    "        # For words that are not in the database, we assign the rating 0\n",
    "        concreteness_rating = mrc_concreteness.get(token.lower(), 0)\n",
    "\n",
    "        # We only consider words that have a concreteness rating in the database when calculating the mean concreteness.\n",
    "        # This might be problematic.\n",
    "        # It could be good to additionally keep track of the number of unrated words.\n",
    "        if concreteness_rating > 0:\n",
    "            concreteness.append(concreteness_rating)\n",
    "\n",
    "    if len(concreteness) > 0:\n",
    "        return statistics.mean(concreteness)\n",
    "    else:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a document representation on three stylistic features: type-token ratio, average sentence length, average concreteness. **Add more stylistic features to better distinguish between document styles. A good overview of features can be found in this [article](https://link.springer.com/article/10.3758/BF03195564).** Read section \"IDENTIFIER INFORMATION AND MEASURES SUPPLIED BY COH-METRIX\". This [article](https://ep.liu.se/ecp/080/002/ecp12080002.pdf)(section 2) on readability can provide additional information. Both papers focus on formal texts. **Discuss features that could be relevant for less formal data (e.g., Twitter).** One could for example also calculate the emoji-ratio or the average number of typos or the ratio of capitalized words or ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Document' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m avg_sentence_len \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m avg_concreteness \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m processed_articles:\n\u001b[1;32m      9\u001b[0m     doc_representation \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Calculate TTR\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Document' object is not iterable"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "ttr = []\n",
    "avg_sentence_len = []\n",
    "avg_concreteness = []\n",
    "\n",
    "\n",
    "for article in processed_articles:\n",
    "\n",
    "    # Calculate TTR\n",
    "    token_frequencies = Counter()\n",
    "    for sentence in article.sentences:\n",
    "        all_tokens =[token.text for token in sentence.tokens]\n",
    "        token_frequencies.update(all_tokens)\n",
    "    num_types = len(token_frequencies.keys())\n",
    "    num_tokens = sum(token_frequencies.values())\n",
    "    tt_ratio = num_types/float(num_tokens)\n",
    "    ttr.append(tt_ratio)\n",
    "\n",
    "    # Calculate average sentence length\n",
    "    sentence_lengths =[len(sentence.tokens) for sentence in article.sentences]\n",
    "    avg_sentence_len.append(statistics.mean(sentence_lengths))\n",
    "\n",
    "    # Calculate concreteness\n",
    "    tokens = [word.lemma for word in sentence.words]\n",
    "    concreteness =[calculate_concreteness(tokens, mrc) for sentence in article.sentences]\n",
    "    avg_concreteness.append(statistics.mean(concreteness))\n",
    "\n",
    "    # Calculate other metrics\n",
    "    # ...\n",
    "\n",
    "# Add the information to the data frame\n",
    "news_content[\"Type-Token Ratio\"] = ttr\n",
    "news_content[\"Avg Sentence Length\"] = avg_sentence_len\n",
    "news_content[\"Avg Concreteness\"] = avg_concreteness\n",
    "news_content.to_csv(\"../data/toy_stylistic_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The document representations can now be used to perform clustering or classification. If we use neural network classifiers, the document representations are usually learned directly. In this case, it can be interesting to test if stylistic features are implicitly contained in the learned representations (this is called *probing*). Keep in mind that this is just a toy example and that it is your job to come up with more advanced stylistic analyses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaD2023",
   "language": "python",
   "name": "lad2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
