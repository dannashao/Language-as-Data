{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1.3: Extracting Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use the Google News API to search for news: \n",
    "\n",
    "https://news.google.com/?hl=en-US&gl=US&ceid=US:en\n",
    "\n",
    "We learn how to extract some metadata from the API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Queries in different languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Google News API, we can specify the query (*q*) and the language (*gl*). The language needs to be abbreviated according to the two-letter ISO-639-1 code. \n",
    "\n",
    "**Play with different queries and languages.** \n",
    "\n",
    "Note: There are different ISO code classifications for languages. ISO-639-1 is the oldest one and uses two letters. More recent schemes use three letters to include more languages (living and extinct): \n",
    "* https://www.iso.org/iso-639-language-codes.html \n",
    "* https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query URL is: http://news.google.com/?q=veganism&gl=en\n"
     ]
    }
   ],
   "source": [
    "from util_html import *\n",
    "\n",
    "topic ='veganism'\n",
    "language='en'\n",
    "base_url = \"http://news.google.com/\"\n",
    "query = topic.lower()\n",
    "\n",
    "# Make sure you understand how this string is composed. \n",
    "full_query = \"?q={0}&gl={1}\".format(query, language)\n",
    "query_url = (base_url + full_query)\n",
    "print(\"The query URL is:\", query_url)\n",
    "\n",
    "query_content = url_to_html(query_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google News lists many articles for each query. As with the NOS-articles, we first want to extract the links. If you click on the links, you will notice that Google News does not write own articles, but just lists articles from other sources. In the following function, we try to extract metadata from the html. \n",
    "\n",
    "This particular strategy for metadata extraction only works for this version of Google News.\n",
    "If you use another engine or if their code changes, you will need to adapt the metadata extraction. \n",
    "\n",
    "**Make sure to add additional printouts to inspect the html content and understand how we find the metadata.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_metadata_googlenews(article):\n",
    "    # Extract the publication date\n",
    "    time = article.find('time')\n",
    "    if time:\n",
    "        datetime = time.get('datetime')\n",
    "        date, time = datetime.split(\"T\")\n",
    "    else:\n",
    "        date = \"\"\n",
    "        time = \"\"\n",
    "    # Discover the structure in the data\n",
    "    technical_data, title_html, publisher_html = article.find_all('a')\n",
    "        \n",
    "    # Extract meta data\n",
    "    publisher = publisher_html.contents[0]\n",
    "    title = title_html.contents[0]\n",
    "    url = title_html.get('href')        \n",
    "        \n",
    "    # The URL is a redirect from the Google page. Let's re-create the original URL form this\n",
    "    article_redirect = base_url + url\n",
    "    article_url = requests.get(article_redirect).url\n",
    "        \n",
    "    return date, time, publisher, title, article_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extracting Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In util_html.py, you find two additional functions: *parse_author* and *parse_news_text*. These functions try to extract the author and the text from each article. Note, that the functions are only approximations. They might fail because we do not know the html structure of every publisher. \n",
    "\n",
    "**If you are an advanced programmer, check the code of the functions and make sure you understand it.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-20 12:22:11Z publisher: Clevelandmagazine.com\n",
      "https://clevelandmagazine.com/food-drink/articles/picked-proteins-offers-an-alternative-to-meat-for-vegans\n",
      "author: \n",
      "title: Picked Proteins Offers An Alternative To Meat For Vegans\n",
      "Scott Roger didn’t miss much once he went vegan. But his cravings for pepperoni led him on a quest t\n",
      "\n",
      "2020-10-18 07:16:42Z publisher: New Bloom\n",
      "https://newbloommag.net/2020/10/18/chang-veganism-commentary/\n",
      "author: \n",
      "title: Popular YouTube Video by Chang Chih-chyi Misrepresents Veganism\n",
      "FAMOUS TAIWANESE Youtube influencer, Chang Chih-chyi, made a video about Veganism that is, at best, \n",
      "\n",
      "2020-10-11 07:00:00Z publisher: Telegraph.co.uk\n",
      "https://www.telegraph.co.uk/health-fitness/nutrition/diet/gave-veganism-health-improved-instantly/\n",
      "author: Flic Everett\n",
      "title: 'I gave up veganism and my health improved instantly'\n",
      " Although many advocates of veganism remain healthy, after two years of health issues, I’m admitting\n",
      "\n",
      "  publisher: RADIO.COM\n",
      "https://www.radio.com/alt1037dfw/blogs/luckey/doctors-say-parents-who-raise-their-kids-vegans-should-be-prosecuted\n",
      "author: \n",
      "title: Doctors Say Parents Who Raise Their Kids As Vegans Should Be Prosecuted\n",
      "\n",
      "\n",
      "2020-10-21 10:32:51Z publisher: Chico Enterprise-Record\n",
      "https://www.chicoer.com/2020/10/21/pumpkins-and-pasta-for-a-spooky-october-north-valley-vegan/\n",
      "author: By Natalie Hanson | nhanson@chicoer.com | Chico Enterprise-Record\n",
      "title: Vegans get a chance with Halloween candy, this year at home | North Valley Vegan\n",
      "CHICO — Here’s hoping for a cooler, safer holiday for all, despite COVID-19, now that Halloween time\n",
      "\n",
      "2020-10-07 07:00:00Z publisher: Anti Aging News\n",
      "https://worldhealth.net/news/these-are-biggest-myths-truths-about-veganism/\n",
      "author: \n",
      "title: These Are The Biggest Myths & Truths About Veganism\n",
      "\n",
      "\n",
      "2020-09-30 17:20:54Z publisher: Forbes\n",
      "https://www.forbes.com/sites/jonisweet/2020/09/30/ranked-20-best-cities-for-vegans-and-vegetarians-in-the-us/\n",
      "author: Joni Sweet\n",
      "title: Ranked: 20 Best Cities For Vegans And Vegetarians In The U.S.\n",
      "Portland, Oregon, is the best city for vegetarians and vegans in the U.S. The numbers don’t lie: The\n",
      "\n",
      "2020-10-01 07:00:00Z publisher: Harvard Political Review\n",
      "https://harvardpolitics.com/more-than-veganism/\n",
      "author: \n",
      "title: “Vegan” Shouldn't Be The Last Word in Sustainability\n",
      "\n",
      "\n",
      "2020-10-17 17:00:26Z publisher: The Guardian\n",
      "https://www.theguardian.com/commentisfree/2020/oct/17/sorry-but-bangers-and-burgers-belong-to-vegans-and-vegetarians-too\n",
      "author: Barbara Ellen\n",
      "title: Sorry, but bangers and burgers belong to vegans and vegetarians too\n",
      " Sat 17 Oct 2020 18.00 BST The meat lobby may be powerful, but is it entitled to cultural ownership \n",
      "\n",
      "2020-10-14 07:00:00Z publisher: VegNews\n",
      "https://vegnews.com/2020/10/joaquin-phoenix-on-veganism-the-environment-and-social-justice-a-vegnews-exclusive-interview\n",
      "author: \n",
      "title: Joaquin Phoenix on Veganism, the Environment, and Social Justice: A VegNews Exclusive Interview\n",
      "When Joaquin Phoenix got to the Oscars podium earlier this year and finished his clean sweep of awar\n",
      "\n"
     ]
    }
   ],
   "source": [
    "articles = query_content.find_all('article')\n",
    "\n",
    "max = 10\n",
    "for i, article in enumerate(articles):\n",
    "    if i < max: \n",
    "        \n",
    "        date, time, publisher, title, article_url = extract_metadata_googlenews(article)\n",
    "        \n",
    "        article_content = url_to_html(article_url)   \n",
    "        author = parse_author(article_content)\n",
    "        content = parse_news_text(article_content)\n",
    "        \n",
    "        print(date, time, \"publisher:\", publisher)\n",
    "        print(article_url)\n",
    "        print(\"author:\", author)  \n",
    "        print(\"title:\", title) \n",
    "        print(content[:100])\n",
    "        print()\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Saving results as TSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standardized open format for storing the content of multiple variables are CSV files. CSV stands for comma-separated values. CSV files are text-based, but when they are imported to a spreadsheet program such as Excel, they are displayed as a table. Lines in the text file are interpreted as rows; commas in the text file are interpreted as separators for columns.  \n",
    "\n",
    "Most programmers prefer to use TSV files. In these files, the values are separated by tabulators (\"\\t\") instead of commas. Both variants can be easily processed, but you need to know which separator has been used. \n",
    "\n",
    "**If necessary, recap information on CSV and TSV files in [Chapter 16](https://github.com/cltl/python-for-text-analysis/blob/master/Chapters/Chapter%2016%20-%20Data%20formats%20I%20(CSV%20and%20TSV).ipynb) of the python course.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Specify query\n",
    "base_url = \"http://news.google.com/\"\n",
    "query='veganism'\n",
    "language='en'\n",
    "\n",
    "# We can restrict the search result to the last 48 hours (48h), or 3 days (3d) or even to the last year (1y)\n",
    "# Note, however that this is a relative date, which makes it difficult to reproduce the retrieval at a later time!\n",
    "time=\"48h\"\n",
    "\n",
    "# Extract data\n",
    "\n",
    "full_query = \"?q={0}&hl={1}&when=\".format(query.lower(), language, time)\n",
    "query_url = (base_url + full_query)\n",
    "query_content = url_to_html(query_url)\n",
    "articles = query_content.find_all('article')\n",
    "\n",
    "outfile = \"../results/googlenews_results/\" + query +\"_overview.tsv\"\n",
    "\n",
    "# Extract metadata and write \n",
    "with open(outfile, \"w\") as f:\n",
    "    f.write(\"Publication Date\\tTime\\tPublisher\\tAuthor\\tTitle\\tURL\\tText\\n\")\n",
    "    \n",
    "    for i, article in enumerate(articles):\n",
    "        \n",
    "        # Extract metadata\n",
    "        date, time, publisher, title, article_url = extract_metadata_googlenews(article)\n",
    "        \n",
    "        # Extract content\n",
    "        article_content = url_to_html(article_url)\n",
    "        author = parse_author(article_content)\n",
    "        content = parse_news_text(article_content)\n",
    "        \n",
    "        # We remove the newlines from the content, so that we can easily store it in a single line. \n",
    "        # Keep in mind, that newlines can also carry meaning.\n",
    "        # For example, they separate paragraphs and this information is lost in the analysis, if we remove them. \n",
    "        content = content.replace(\"\\n\", \"\")\n",
    "        \n",
    "        # We want the fields to be separated by tabulators (\\t)\n",
    "        output = \"\\t\".join([date, time, publisher, author, title, article_url, content])\n",
    "        f.write(output +\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Inspect the results.\n",
    "\n",
    "You will notice that we do not always find a value for the author. There can be two reasons for that: \n",
    "- The author name is not provided by the publisher.\n",
    "- Our code cannot find it.\n",
    "\n",
    "Double-check on the website which explanation holds. When we are working with automatic methods, we will always be confronted with the issue of missing data. \n",
    "\n",
    "**Discuss how this can affect the methodology and interpretation of your experiments.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Unfortunately, the Google News API is no longer maintained. It is still running but it is not known for how long."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaD",
   "language": "python",
   "name": "lad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
