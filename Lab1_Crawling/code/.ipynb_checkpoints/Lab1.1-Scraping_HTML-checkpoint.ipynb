{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1.1: Scraping HTML content from the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, you see web content in a browser. The browser displays web pages which are either created as static HTML or generated dynamically from databases or other formats. One way to create a corpus from web pages is to download the HTML source.\n",
    "\n",
    "HTML stands for *Hyper Text Markup Language* and it contains more than just the text of the web page. It includes instructions to the browser how to render the content so that people can easily access it. It may also contain other parts such as: Java Script code to run little programs, hyperlinks to other webpages, images, videos, or comments made by the people that created the page. \n",
    "\n",
    "In the python course, you have already seen how to use the *request* package to download the web page as an HTML object. In order to access different elements of the HTML object, we will use the package *beautifulsoup4* which is build on top of *html5lib*. \n",
    "\n",
    "Please make sure that you have prepared your [technical setup](https://canvas.vu.nl/courses/56534/pages/getting-started). Activate the virtual environment LaD and make sure that you choose LaDKernel as a kernel for this notebook. Now, we can start scraping web content as HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scraping HTML content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import html5lib\n",
    "\n",
    "\n",
    "url =\"http://cltl.nl\"\n",
    "result = requests.get(url)\n",
    "html = result.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable *html* now contains the HTML content from our CLTL web page. Let's have a closer look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The start of the HTML content:\n",
      "<!DOCTYPE html>\n",
      "<!--[if IE 7]>\n",
      "<html class=\"ie ie7\" lang=\"en-US\" xmlns:fb=\"https://www.facebook.com/2008/fbml\" xmlns:addthis=\"https://www.addthis.com/help/api-spec\" >\n",
      "<![endif]-->\n",
      "<!--[if IE 8]>\n",
      "<html class=\"ie ie8\" lang=\"en-US\" xmlns:fb=\"https://www.facebook.com/2008/fbml\" xmlns:addthis=\"https://www.addthis.com/help/api-spec\" >\n",
      "<![endif]-->\n",
      "<!--[if !(IE 7) & !(IE 8)]><!-->\n",
      "<html lang=\"en-US\" xmlns:fb=\"https://www.facebook.com/2008/fbml\" xmlns:addthis=\"https://www.addthis.com/help/api-spec\" >\n",
      "<!--<![endif]-->\n",
      "<head>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width\" />\n",
      "<title>CLTL | the Computational Linguistics &amp; Text Mining Lab</title>\n",
      "<link rel=\"profile\" href=\"http://gmpg.org/xfn/11\" />\n",
      "<link rel=\"pingback\" href=\"http://www.cltl.nl/xmlrpc.php\" />\n",
      "<!--[if lt IE 9]>\n",
      "<script src=\"http://www.cltl.nl/wp-content/themes/twentytwelve/js/html5.js\" type=\"text/javascript\"></script>\n",
      "<![endif]-->\n",
      "<link rel='dns-prefetch' href='//s7.addthis.com' />\n",
      "<link rel='dns-prefetch' href='//cdn.datatables.net' />\n",
      "<link rel='dns-prefetch' href='//cdnjs.cloudflare.com' />\n",
      "<link rel='dns-prefetch' href='//www.google.com' />\n",
      "<link rel='dns-prefetch' href='//wordpress.let.vupr.nl' />\n",
      "<link rel='dns-prefetch' href='//fonts.googleapis.com' />\n",
      "<link rel='dns-prefetch' href='//s.w.org' />\n",
      "<link href='https://fonts.gstatic.com' crossorigin rel='preconnect' />\n",
      "<link rel=\"alternate\" type=\"application/rss+xml\" title=\"CLTL &raquo; Feed\" href=\"http://www.cltl.nl/feed/\" />\n",
      "<link rel=\"alternate\" type=\"application/rss+xml\" title=\"CLTL &raquo; Comments Feed\" href=\"http://www.cltl.nl/comments/feed/\" />\n",
      "<link rel=\"alternate\" type=\"text/calendar\" title=\"CLTL &raquo; iCal Feed\" href=\"http://www.cltl.nl/events/?ical=1\" />\n",
      "\t\t<script type=\"text/javascript\">\n",
      "\t\t\twindow._wpemojiSettings = {\"baseUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/11\\/72x72\\/\",\"ext\":\".png\",\"svgUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/11\\/svg\\/\",\"svgExt\":\".svg\",\"source\":{\"concatemoji\":\"http:\\/\\/www.cltl.nl\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# An HTML document starts with a header that specifies a lot of metadata. \n",
    "# Let's print the first 2000 characters:\n",
    "print('The start of the HTML content:')\n",
    "print(html[:2000])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the content is structured by so-called tags between \"<\" and \">\". Don't worry if the header looks confusing. The main content of the web page can be found within the ```<body> .... </body>``` tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beginning of the body:\n",
      "</head>\n",
      "\n",
      "<body class=\"home page-template-default page page-id-25 custom-background do-etfw tribe-no-js custom-background-white custom-font-enabled\">\n",
      "<div id=\"page\" class=\"hfeed site\">\n",
      "\t<header id=\"masthead\" class=\"site-header\" role=\"banner\">\n",
      "\t\t<hgroup>\n",
      "\t\t\t<h1 class=\"site-title\"><a href=\"http://www.cltl.nl/\" title=\"CLTL\" rel=\"home\">CLTL</a></h1>\n",
      "\t\t\t<h2 class=\"site-description\">the Computational Linguistics &amp; Text Mining Lab</h2>\n",
      "\t\t</hgroup>\n",
      "\n",
      "\t\t<nav id=\"site-navigation\" class=\"main-navigation\" role=\"navigation\">\n",
      "\t\t\t<button class=\"menu-toggle\">Menu</button>\n",
      "\t\t\t<a class=\"assistive-text\" href=\"#content\" title=\"Skip to content\">Skip to content</a>\n",
      "\t\t\t<div class=\"nav-menu\"><ul>\n",
      "<li class=\"current_page_item\"><a href=\"http://www.cltl.nl/\">Home</a></li><li class=\"page_item page-item-31\"><a href=\"http://www.cltl.nl/people/\">People</a></li>\n",
      "<li class=\"page_item page-item-33 page_item_has_children\"><a href=\"http://www.cltl.nl/projects/\">Projects\n"
     ]
    }
   ],
   "source": [
    "# In this example, the body starts after around 12050 characters. \n",
    "print('The beginning of the body:')\n",
    "print(html[12050:13000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somewhere in the middle:\n",
      "\n",
      "ute</a>.</p>\n",
      "<p>&nbsp;</p>\n",
      "<h3>Our research</h3>\n",
      "<p>The Computational Linguistics and Text Mining Lab (CLTL) models the <a href=\"http://www.understandinglanguagebymachines.org\">understanding of natural language by machines</a>. Machines that can read texts and understand what it is about (what, who, when, where), but also machines that create powerful distributional language models from large volume of text using Deep Learning techniques. Our research tries to obtain a better understanding of so-called backbone models, reveal biases and unwanted errors but also to combine distributional approaches with explicit symbolic models to add explanatory power.&nbsp;Please go <a href=\"https://cltl.github.io\">here</a> for an overview of our current research and links to more information.</p>\n",
      "<p>We see language as a reference system that connects people and systems to their perception of the world. Identity, reference and perspectives are central themes in our research and are studied in combination. You can read more about the Theory of Identify, Reference and Perspective (TIRP)&nbsp;<a href=\"http://www.understandinglanguagebymachines.org/tirp/\">here</a>. In our research projects on Communicative Robots, many of our ideas come together:&nbsp;<a href=\"http://makerobotstalk.nl\">http://makerobotstalk.nl</a>&nbsp;In these projects, we try to build robots that communicate with people in real-world situations taking perceptions of the contexts into account and the shared common ground.</p>\n",
      "<h3>What we teach you as a student</h3>\n",
      "<p>CLTL trains students to prepare them for academic careers in Computational Linguistics but also for the industry as Linguistics Engineers for Text Mining. Students at CLTL learn all the technical skills needed but specifically how to combine these with their knowledge and passion for language. If you are interested to study with us and become ready for the job market with your language skills, check out our teaching programmes: <a href=\"http://www.cltl.n\n"
     ]
    }
   ],
   "source": [
    "# I looked for a region that contains some text.  \n",
    "print('Somewhere in the middle:\\n')\n",
    "print(html[30000:32000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the text content that we are interested in is still scattered and not easy to extract. Here are some examples for structuring tags and symbols: \n",
    "* &lt;p> stands for the beginning of a paragraph, &lt;/p> for the end\n",
    "* &lt;a href=... starts a link \n",
    "* &lt;h1> stands for a big headline, &lt;h2> stands for a smaller headline \n",
    "* &amp;#8220; and &amp;#8221; are opening and closing quotation marks. \n",
    "\n",
    "You do not need to learn all these terms and symbols, just know how to look them up in case you need them. \n",
    "(https://www.w3schools.com/tags/ref_byfunc.asp, https://dev.w3.org/html5/html-author/charref)\n",
    "    \n",
    "**Take some time to print different parts of the HTML content and compare them to what you see in the browser. Play around with other urls!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting text from HTML\n",
    "In order to reduce the complex HTML content to the main text content, we use an HTML parser called BeautifulSoup. This parser processes the different opening and closing tags and extracts only the content that seems to be textual. Compare the different outputs of the functions *prettify()* and *get_text()*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e.org/\" rel=\"noopener\" target=\"_blank\">\n",
      "          Network Institute\n",
      "         </a>\n",
      "         .\n",
      "        </p>\n",
      "        <p>\n",
      "        </p>\n",
      "        <h3>\n",
      "         Our research\n",
      "        </h3>\n",
      "        <p>\n",
      "         The Computational Linguistics and Text Mining Lab (CLTL) models the\n",
      "         <a href=\"http://www.understandinglanguagebymachines.org\">\n",
      "          understanding of natural language by machines\n",
      "         </a>\n",
      "         . Machines that can read texts and understand what it is about (what, who, when, where), but also machines that create powerful distributional language models from large volume of text using Deep Learning techniques. Our research tries to obtain a better understanding of so-called backbone models, reveal biases and unwanted errors but also to combine distributional approaches with explicit symbolic models to add explanatory power. Please go\n",
      "         <a href=\"https://cltl.github.io\">\n",
      "          here\n",
      "         </a>\n",
      "         for an overview of our current research and links to more information.\n",
      "        </p>\n",
      "        <p>\n",
      "         We see language as a reference system that connects people and systems to their perception of the world. Identity, reference and perspectives are central themes in our research and are studied in combination. You can read more about the Theory of Identify, Reference and Perspective (TIRP)\n",
      "         <a href=\"http://www.understandinglanguagebymachines.org/tirp/\">\n",
      "          here\n",
      "         </a>\n",
      "         . In our research projects on Communicative Robots, many of our ideas come together:\n",
      "         <a href=\"http://makerobotstalk.nl\">\n",
      "          http://makerobotstalk.nl\n",
      "         </a>\n",
      "         In these projects, we try to build robots that communicate with people in real-world situations taking perceptions of the contexts into account and the shared common ground.\n",
      "        </p>\n",
      "        <h3>\n",
      "         What we teach you as a student\n",
      "        </h3>\n",
      "        <p>\n",
      "         CLTL trains students to prepare them for academic careers in Computational Linguistics but\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "parser_content = BeautifulSoup(html, 'html5lib')\n",
    "\n",
    "# The function prettify() provides the HTML content in a more readable way.\n",
    "# Note that due to the additional line breaks, the character count changes for the same region of text. \n",
    "print(parser_content.prettify()[36700:38700])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t is about (what, who, when, where), but also machines that create powerful distributional language models from large volume of text using Deep Learning techniques. Our research tries to obtain a better understanding of so-called backbone models, reveal biases and unwanted errors but also to combine distributional approaches with explicit symbolic models to add explanatory power. Please go here for an overview of our current research and links to more information.\n",
      "We see language as a reference system that connects people and systems to their perception of the world. Identity, reference and perspectives are central themes in our research and are studied in combination. You can read more about the Theory of Identify, Reference and Perspective (TIRP) here. In our research projects on Communicative Robots, many of our ideas come together: http://makerobotstalk.nl In these projects, we try to build robots that communicate with people in real-world situations taking perceptions of the contexts into account and the shared common ground.\n",
      "What we teach you as a student\n",
      "CLTL trains students to prepare them for academic careers in Computational Linguistics but also for the industry as Linguistics Engineers for Text Mining. Students at CLTL learn all the technical skills needed but specifically how to combine these with their knowledge and passion for language. If you are interested to study with us and become ready for the job market with your language skills, check out our teaching programmes: research and text mining.\n",
      "Many of our students started with a background in linguistics only but within a year they learned to use their skills and knowledge to analyse language as data. Follow this link for examples of our student projects to see what they did and what you can learn to do as well.\n",
      "Our application perspective is Text Mining: technology that is used to automatically extract knowledge and information from text and to turn unstructured data in structured data that can be \n"
     ]
    }
   ],
   "source": [
    "# The function get_text() extracts textual content from the HTML.\n",
    "# Again, the character count for our text region changed because all tags are now being ignored. \n",
    "print(parser_content.get_text()[6000:8000])\n",
    "\n",
    "# Uncomment the line below to look at the full output for comparison: \n",
    "# print(parser_content.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the full output of the get_text() method, you notice that it still contains unnecessary elements such as scripts. We remove them using the method extract(). If you want to know more about this, look at the [documentation] (https://www.crummy.com/software/BeautifulSoup/bs4/doc/). But for the moment, I recommend to just accept that this works.  \n",
    "\n",
    "A regular expression helps us to get rid of unnecessary newlines. **If you are new to Python, take some time here to understand what is happening and recap how to use regular expressions. These are very common data processing steps and you will need them very often.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CLTL | the Computational Linguistics & Text Mining Lab   CLTL the Computational Linguistics & Text Mining Lab Menu Skip to content HomePeople Projects Current projects Rethinking News Recommender Systems (2020-2024) ALANI (2020-2024) Understanding of Language by Machines Hybrid Intelligence (2019-2029) Make Robots Talk and Think (2020-2024) Robot Leolani (ULM5) Weekend of Science 2018: Talking with Robots Leolani in Brno 2018 Weekend of Science 2017: Talking with Robots Dutch Framenet (2019-2023) CLARIAH VU University Research Fellow QuPiD2 Word, Sense and Reference Digital Humanities Open Dutch Wordnet Global WordNet Grid Global WordNet Association Previous projects The Reference Machine NewsReader Reading between the lines BiographyNet Language, Knowledge and People in Perspective Discriminatory Micro Portraits CLIN26 Visualizing Uncertainty and Perspectives HHuCap SERPENS Investigating Criminal Networks INclusive INsight Can we Handle the News (EYR4) OpeNER Mapping Notes and Nodes in Networks KYOTO Cornetto-LMF-RDF From sentiments and opinions in texts to positions of political parties Semantics of History TH@SIS DutchSemCor FLaReNet Cornetto DutchSemCor Pilotgrant StoreTelling Theory of Identity, Reference and Perspective (TIRP) Centres & Associations Global WordNet Association Dutch Terminology Service Centre Centre for Digital Humanities Amsterdam Education Master Human Language Technology Master Text Mining Other courses Text Mining Projects Student projects Text Mining 2018 Student Projects Text Mining 2017 Student Projects Text Mining 2016 Forensic Linguistics Minor Digital Humanities and Social Analytics Course projects Graduates and Careers Meet & Greet companies & CLTL-students Procedure internships master students Meet & Greet CLTL-students December 3, 2020 Meet & Greet December 13, 2019 Meet & Greet December 8, 2017 Theses and internships Master’s theses Thesis topics Internships Student Assistant Projects Publications Publications CLTL Publication Requirements Resources Corpora and Lexica KAF Demos Open Source Dutch WordNet Wordnet Similarity Demo Wordnet Graphs Cornetto Ambiguity demo Uncertainty Visualization The VU Sound Corpus Soundtags Wsd4Kids Software Ontotagger Kybot KafSaxParser MultiwordTagger KafNafAnnotator EventCoreference WordnetTools Computer Facilities News Home Computational Linguistics & Text Mining Lab The Computational Linguistics and Text Mining Lab (CLTL) with Prof.Dr. Piek Vossen as director is part of the Department of Language, Literature and Communication of the Faculty of Humanities of the Vrije Universiteit Amsterdam, and of the Network Institute.   Our research The Computational Linguistics and Text Mining Lab (CLTL) models the understanding of natural language by machines. Machines that can read texts and understand what it is about (what, who, when, where), but also machines that create powerful distributional language models from large volume of text using Deep Learning techniques. Our research tries to obtain a better understanding of so-called backbone models, reveal biases and unwanted errors but also to combine distributional approaches with explicit symbolic models to add explanatory power. Please go here for an overview of our current research and links to more information. We see language as a reference system that connects people and systems to their perception of the world. Identity, reference and perspectives are central themes in our research and are studied in combination. You can read more about the Theory of Identify, Reference and Perspective (TIRP) here. In our research projects on Communicative Robots, many of our ideas come together: http://makerobotstalk.nl In these projects, we try to build robots that communicate with people in real-world situations taking perceptions of the contexts into account and the shared common ground. What we teach you as a student CLTL trains students to prepare them for academic careers in Computational Linguistics but also for the industry as Linguistics Engineers for Text Mining. Students at CLTL learn all the technical skills needed but specifically how to combine these with their knowledge and passion for language. If you are interested to study with us and become ready for the job market with your language skills, check out our teaching programmes: research and text mining. Many of our students started with a background in linguistics only but within a year they learned to use their skills and knowledge to analyse language as data. Follow this link for examples of our student projects to see what they did and what you can learn to do as well. Our application perspective is Text Mining: technology that is used to automatically extract knowledge and information from text and to turn unstructured data in structured data that can be used by organisations. This ranges from simple statements and facts, to events, storylines, to opinions and world-views but also fake news, toxic language detection, and the analysis\n"
     ]
    }
   ],
   "source": [
    "# Clean up the content step by step. \n",
    "#1. Remove unnecessary elemens like scripts. \n",
    "for script in parser_content([\"script\", \"style\", \"aside\"]):\n",
    "    script.extract()\n",
    "   \n",
    "text_with_newlines = parser_content.get_text()\n",
    "\n",
    "# 2. We split the text at each newline or tab. \n",
    "# Make sure to recap how to use regular expressions. You will need them very often. \n",
    "import re\n",
    "text_elements = re.split(r'[\\n\\t]+', text_with_newlines)\n",
    "\n",
    "# Now join the text elements by simple white spaces: \n",
    "text_without_newlines = \" \".join(text_elements)\n",
    "\n",
    "print(text_without_newlines[:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our lifes easier, we put all the steps into a single function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_string(url):\n",
    "    \"\"\"\n",
    "    Utility function to get the raw text from a web page.  \n",
    "    It takes a URL string as input and returns the text.\n",
    "    \"\"\"\n",
    "    res = requests.get(url)\n",
    "    html = res.text\n",
    "    parser_content = BeautifulSoup(html, 'html5lib')\n",
    "    \n",
    "    for script in parser_content([\"script\", \"style\", 'aside']):\n",
    "        script.extract()\n",
    "        \n",
    "    # This is a shorter way to write the code for removing the newlines. \n",
    "    # It does the same as above in one step without intermediate variables\n",
    "    return \" \".join(re.split(r'[\\n\\t]+', parser_content.get_text()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply this function to any URL and save the result in a txt-file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"http://cltl.nl\"\n",
    "cltl_content=url_to_string(url)\n",
    "\n",
    "# Save the text content to a file. \n",
    "filename='../results/cltl.txt'\n",
    "with open(filename, 'w', encoding=\"utf-8\") as outfile:\n",
    "    outfile.write(cltl_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the text extract of an HTML page is not clean and linear text because it contains for example menu items. These are glued to the text without proper punctuation or sentence structure. It will be different for every web page and will have an impact on what we represent as language and on the performance of the systems that we run on these texts. **Play around with other URLs to see the differences and think about what kind of text preprocessing could be useful in each case.** \n",
    "\n",
    "In order to be able to access the function url_to_string(url) from other notebooks, we did the following: \n",
    "- We copied the function to a file called *util_html.py*.\n",
    "- We added an empty file called *\\_\\_init\\_\\_.py* to the directory. This file indicates that py-files in this directory can be treated as modules and the functions in these files can be imported. \n",
    "\n",
    "When we need the function in another notebook, we can now just write: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_html import url_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaD2023",
   "language": "python",
   "name": "lad2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
